{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:orange'> Load Model and Apply on Validation Data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from modules.configfile import config\n",
    "from modules.training_helpers import *\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import random as random\n",
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "import importlib\n",
    "import optparse\n",
    "import os\n",
    "import logging\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "try:\n",
    "    logger = logging.getLogger(__file__.split('/')[-1])\n",
    "except:\n",
    "    logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom class to mimic the \"options\" data structure, since optparse doesn't work in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPT:\n",
    "    def __init__(self):\n",
    "        self.defmodelfile = 'cnn_patches'\n",
    "        self.grade = 'HGG'\n",
    "        self.output_name = 'cnn_patches_v1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = OPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Name of output file: /local-scratch/cedar-rm/scratch/asa224/model-snapshots/cnn_patches_v1.h5\n"
     ]
    }
   ],
   "source": [
    "if options.output_name is None:\n",
    "    logger.info('No output name defined, using default values')\n",
    "    options.output_name = os.path.join(config['model_snapshot_location'], 'model_default.h5')\n",
    "    logger.info('Name of output file: {}'.format(options.output_name))\n",
    "else:\n",
    "    options.output_name = os.path.join(config['model_snapshot_location'], options.output_name)\n",
    "    logger.info('Name of output file: {}'.format(options.output_name))\n",
    "\n",
    "if options.defmodelfile is None:\n",
    "    logger.info('No defmodel file name defined, using default model (cnn)')\n",
    "    options.defmodelfile = 'cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/local-scratch/cedar-rm/scratch/asa224/model-snapshots/cnn_patches_v1.h5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options.output_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the module name to load, and open mean_var file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnn_patches.pyc:Setting keras backend data format to \"channels_first\"\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------\n",
    "# open required files\n",
    "# --------------------------------------------------------------------------------------\n",
    "# open mean and variance dictionary\n",
    "\n",
    "mean_var = pickle.load(open(config['saveMeanVarFilepath'+options.grade.upper()], 'rb'))\n",
    "\n",
    "# open new database with cropped images\n",
    "\n",
    "if config['validate_on'] == 'cropped':\n",
    "    hdf5_file = h5py.File(config['hdf5_filepath_cropped'], mode='r')\n",
    "    hdf5_file_g = hdf5_file['preprocessed']\n",
    "else:\n",
    "    hdf5_file = h5py.File(config['hdf5_filepath_prefix'], mode='r')\n",
    "    hdf5_file_g = hdf5_file['original_data']\n",
    "\n",
    "# get the validation data\n",
    "# training_data = hdf5_file_g['training_data_'+options.grade.lower()]\n",
    "# training_data_segmasks = hdf5_file_g['training_data_segmasks_'+options.grade.lower()]\n",
    "\n",
    "if options.defmodelfile is None:\n",
    "    logger.info('No defmodel file name defined, using default model (cnn)')\n",
    "    options.defmodelfile = 'cnn'\n",
    "    \n",
    "# -------------------------------------------------------------------------------------\n",
    "# get model file\n",
    "# -------------------------------------------------------------------------------------\n",
    "# open the model file module\n",
    "modeldefmodule = importlib.import_module('defmodel.'+options.defmodelfile, package=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model, hyperparameters and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnn_patches.pyc:Opening trained model with name /local-scratch/cedar-rm/scratch/asa224/model-snapshots/cnn_patches_v1.h5\n",
      "INFO:cnn_patches.pyc:Model open successful!\n",
      "INFO:cnn_patches.pyc:Opening hyperparameter dictionary with name /local-scratch/cedar-rm/scratch/asa224/model-snapshots/cnn_patches_v1_hyper_dict.p\n",
      "INFO:cnn_patches.pyc:Opened hyperparameter dictionary!\n",
      "INFO:cnn_patches.pyc:Opening history object with name /local-scratch/cedar-rm/scratch/asa224/model-snapshots/cnn_patches_v1_hyper_dict.p\n",
      "INFO:cnn_patches.pyc:Opened history object!\n"
     ]
    }
   ],
   "source": [
    "model, params, history = modeldefmodule.open_model_with_hyper_and_history(name=options.output_name, custom_obj={'dice_coefficient_loss':modeldefmodule.dice_coefficient_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 4, None, None, Non 0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 32, None, None, No 3488      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 32, None, None, No 27680     \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 64, None, None, No 55360     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 4, None, None, Non 6916      \n",
      "=================================================================\n",
      "Total params: 93,444\n",
      "Trainable params: 93,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data of various sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one patient, with 4 modalities, of original size\n",
    "pat1 = np.empty((1, 4, 120, 120, 120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the data with mean and var values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.dataloader import standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 120, 120, 120)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modules.dataloader:Applying to test data using provided values\n"
     ]
    }
   ],
   "source": [
    "pat1_s = standardize(pat1, applyToTest=mean_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(pat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 120, 120, 120)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
